{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Software Design Using ML&AI nWave\n",
    "\n",
    "\n",
    "# 1. Setup\n",
    "\n",
    "To prepare your environment, you need to install some packages\n",
    "\n",
    "# 1.1 Install the necessary packages\n",
    "\n",
    "You need the latest versions of these packages:<br>\n",
    "** Watson Developer Cloud:** a client library for Watson services -- using this for Object Storage which comes free with the ibm bluemix account.<br>\n",
    "** Spacy** a client library for NLP.<br>\n",
    "** Pandas for dataframe.<br>\n",
    "** stop_words: **List of common stop words.<br>\n",
    "** python-boto3:** is a python client for the Boto3 API used for communicating to AWS.<br>\n",
    "** websocket-client: ** is a python client for the Websockets.<br>\n",
    "** pyorient: ** is a python client for the Orient DB.<br><br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Install NLTK: **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: nltk in /anaconda3/lib/python3.6/site-packages (3.2.5)\n",
      "Requirement not upgraded as not directly required: six in /anaconda3/lib/python3.6/site-packages (from nltk) (1.11.0)\n",
      "Collecting python-swiftclient\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/95/d4/393d9f835abdc8085edf6d1007e9954af33ac4ff7c160db694c25dcbadb1/python_swiftclient-3.5.0-py2.py3-none-any.whl (77kB)\n",
      "\u001b[K    100% |████████████████████████████████| 81kB 225kB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: six>=1.5.2 in /anaconda3/lib/python3.6/site-packages (from python-swiftclient) (1.11.0)\n",
      "Requirement already satisfied: requests>=1.1 in /anaconda3/lib/python3.6/site-packages (from python-swiftclient) (2.18.4)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /anaconda3/lib/python3.6/site-packages (from requests>=1.1->python-swiftclient) (3.0.4)\n",
      "Requirement already satisfied: idna<2.7,>=2.5 in /anaconda3/lib/python3.6/site-packages (from requests>=1.1->python-swiftclient) (2.6)\n",
      "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /anaconda3/lib/python3.6/site-packages (from requests>=1.1->python-swiftclient) (1.22)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /anaconda3/lib/python3.6/site-packages (from requests>=1.1->python-swiftclient) (2018.1.18)\n",
      "Installing collected packages: python-swiftclient\n",
      "Successfully installed python-swiftclient-3.5.0\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade nltk\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Install Boto3 client for AWS communication thorugh CLI **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: boto3 in /anaconda3/lib/python3.6/site-packages (1.7.11)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /anaconda3/lib/python3.6/site-packages (from boto3) (0.9.3)\n",
      "Requirement already satisfied: botocore<1.11.0,>=1.10.11 in /anaconda3/lib/python3.6/site-packages (from boto3) (1.10.11)\n",
      "Requirement already satisfied: s3transfer<0.2.0,>=0.1.10 in /anaconda3/lib/python3.6/site-packages (from boto3) (0.1.13)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\" in /anaconda3/lib/python3.6/site-packages (from botocore<1.11.0,>=1.10.11->boto3) (2.6.1)\n",
      "Requirement already satisfied: docutils>=0.10 in /anaconda3/lib/python3.6/site-packages (from botocore<1.11.0,>=1.10.11->boto3) (0.14)\n",
      "Requirement already satisfied: six>=1.5 in /anaconda3/lib/python3.6/site-packages (from python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\"->botocore<1.11.0,>=1.10.11->boto3) (1.11.0)\n",
      "\u001b[31mawscli 1.15.10 has requirement botocore==1.10.10, but you'll have botocore 1.10.11 which is incompatible.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install boto3 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Install stop_words **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: stop-words in /anaconda3/lib/python3.6/site-packages (2015.2.23.1)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install stop-words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Install websocket client: **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: websocket-client in /anaconda3/lib/python3.6/site-packages (0.47.0)\r\n",
      "Requirement already satisfied: six in /anaconda3/lib/python3.6/site-packages (from websocket-client) (1.11.0)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install websocket-client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Install pyorient: **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: awscli in /anaconda3/lib/python3.6/site-packages (1.15.10)\n",
      "Requirement already satisfied: colorama<=0.3.7,>=0.2.5 in /anaconda3/lib/python3.6/site-packages (from awscli) (0.3.7)\n",
      "Collecting botocore==1.10.10 (from awscli)\n",
      "  Using cached https://files.pythonhosted.org/packages/77/c9/a40ebce24bbab4c7986fccdac9dade097385ad2feae73dcc47d31a1b4dc8/botocore-1.10.10-py2.py3-none-any.whl\n",
      "Requirement already satisfied: s3transfer<0.2.0,>=0.1.12 in /anaconda3/lib/python3.6/site-packages (from awscli) (0.1.13)\n",
      "Requirement already satisfied: rsa<=3.5.0,>=3.1.2 in /anaconda3/lib/python3.6/site-packages (from awscli) (3.4.2)\n",
      "Requirement already satisfied: docutils>=0.10 in /anaconda3/lib/python3.6/site-packages (from awscli) (0.14)\n",
      "Requirement already satisfied: PyYAML<=3.12,>=3.10 in /anaconda3/lib/python3.6/site-packages (from awscli) (3.12)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\" in /anaconda3/lib/python3.6/site-packages (from botocore==1.10.10->awscli) (2.6.1)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /anaconda3/lib/python3.6/site-packages (from botocore==1.10.10->awscli) (0.9.3)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /anaconda3/lib/python3.6/site-packages (from rsa<=3.5.0,>=3.1.2->awscli) (0.4.2)\n",
      "Requirement already satisfied: six>=1.5 in /anaconda3/lib/python3.6/site-packages (from python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\"->botocore==1.10.10->awscli) (1.11.0)\n",
      "\u001b[31mboto3 1.7.11 has requirement botocore<1.11.0,>=1.10.11, but you'll have botocore 1.10.10 which is incompatible.\u001b[0m\n",
      "Installing collected packages: botocore\n",
      "  Found existing installation: botocore 1.10.11\n",
      "    Uninstalling botocore-1.10.11:\n",
      "      Successfully uninstalled botocore-1.10.11\n",
      "Successfully installed botocore-1.10.10\n",
      "Requirement already satisfied: pyorient in /Users/swaroopmishra/.local/lib/python3.6/site-packages (1.5.5)\n",
      "\u001b[31mboto3 1.7.11 has requirement botocore<1.11.0,>=1.10.11, but you'll have botocore 1.10.10 which is incompatible.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip install awscli\n",
    "! pip install pyorient --user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.2 Import packages and libraries \n",
    "\n",
    "Import the packages and libraries that you'll use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import spacy\n",
    "\n",
    "import re\n",
    "import nltk\n",
    "from nltk.cluster.util import cosine_distance\n",
    "from stop_words import get_stop_words\n",
    "import numpy\n",
    "\n",
    "import boto3\n",
    "from botocore.client import Config\n",
    "\n",
    "import websocket\n",
    "import _thread\n",
    "import time\n",
    "\n",
    "from io import BytesIO\n",
    "import pandas as pd\n",
    "import json\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Configuration\n",
    "\n",
    "Add configurable items of the notebook below\n",
    "## 2.1 Add your service credentials if any required( this is where you need to add credentials of infrastructure you are using to store data etc)\n",
    "\n",
    "\n",
    "Run the cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Add your service credentials for S3\n",
    "\n",
    "You must create S3 bucket service on AWS. To access data in a file in Object Storage, you need the Object Storage authentication credentials. Insert the Object Storage authentication credentials as credentials_1 in the following cell after removing the current contents in the cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @hidden_cell\n",
    "# The following code contains the credentials for a file in your IBM Cloud Object Storage.\n",
    "# You might want to remove those credentials before you share your notebook.\n",
    "credentials_1 = {\n",
    "    'ACCESS_KEY_ID': 'AKIAI2HNLNKRJAZABJOQ',\n",
    "    'ACCESS_SECRET_KEY': 'DLracSjxQKTWSOjyGAX+yyC+PjRTx0c8r58nt/Vu',\n",
    "    'BUCKET': 'software-testing-pyscript'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.  Spacy Text Classification\n",
    "\n",
    "Write the classification related utility functions in a modularalized form.\n",
    "Define functions based on the text classification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Correlate text content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Persistence and Storage\n",
    "## 5.1 Configure Object Storage Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 =    boto3.resource('s3',\n",
    "                    aws_access_key_id=credentials_1['ACCESS_KEY_ID'],\n",
    "                    aws_secret_access_key=credentials_1['ACCESS_SECRET_KEY'],\n",
    "                    config=Config(signature_version='s3v4')\n",
    "                     )\n",
    "\n",
    "#def get_file(filename):\n",
    "#    '''Retrieve file from Cloud Object Storage'''\n",
    "#    fileobject = cos.get_object(Bucket=credentials_1['BUCKET'], Key=filename)['Body']\n",
    "#    return fileobject\n",
    "\n",
    "#def load_string(fileobject):\n",
    "#    '''Load the file contents into a Python string'''\n",
    "#    text = fileobject.read()\n",
    "#    return text\n",
    "\n",
    "#def load_df(fileobject,sheetname):\n",
    "#    '''Load file contents into a Pandas dataframe'''\n",
    "#    excelFile = pd.ExcelFile(fileobject)\n",
    "#    df = excelFile.parse(sheetname)\n",
    "#    return df\n",
    "\n",
    "def put_file(filename, filecontents):\n",
    "    '''Write file to Cloud Object Storage'''\n",
    "    resp = s3.put_object(Bucket=credentials_1['BUCKET'], Key=filename, Body=filecontents)\n",
    "    #resp = s3.Bucket(Bucket=credentials_1['BUCKET']).put_object(Key=filename, Body=filecontents)\n",
    "    return resp\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 OrientDB client - functions to connect, store and retrieve data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Connect to OrientDB **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** OrientDB Core functions **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** OrientDB Insights **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.1 Global variables and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Name of the excel file with data in Object Storage\n",
    "dataFileName = \"sample_data.xlsx\"\n",
    "\n",
    "# Name of the config file in Object Storage\n",
    "configFileName = \"sample_config.txt\"\n",
    "\n",
    "# Config contents\n",
    "config = None;\n",
    "\n",
    "# Data file\n",
    "datafile = None\n",
    "\n",
    "# Requirements dataframe\n",
    "requirements_sheet_name = \"Requirements\"\n",
    "requirements_df = None\n",
    "\n",
    "# Defects dataframe\n",
    "defects_sheet_name = \"Defects\"\n",
    "defects_df = None\n",
    "\n",
    "# Testcases dataframe\n",
    "testcases_sheet_name =\"TestCases\"\n",
    "testcases_df = None\n",
    "\n",
    "def load_artifacts():\n",
    "    \"\"\" Load the artifacts into a pandas dataframe\n",
    "    \"\"\"\n",
    "    global requirements_df \n",
    "    global defects_df \n",
    "    global testcases_df \n",
    "    global config\n",
    "    global datafile\n",
    "    config = load_string(get_file(configFileName))\n",
    "    datafile = get_file(dataFileName)\n",
    "    excel_file = pd.ExcelFile(datafile)\n",
    "    requirements_df = excel_file.parse(requirements_sheet_name)\n",
    "    defects_df = excel_file.parse(defects_sheet_name)\n",
    "    testcases_df = excel_file.parse(testcases_sheet_name)\n",
    "    \n",
    "def prepare_artifact_dataframes():\n",
    "    \"\"\" Prepare artifact dataframes by creating necessary output columns\n",
    "    \"\"\"\n",
    "    global requirements_df \n",
    "    global defects_df \n",
    "    global testcases_df \n",
    "    req_cols_len = len(requirements_df.columns)\n",
    "    def_cols_len = len(defects_df.columns)\n",
    "    tcs_cols_len = len(testcases_df.columns)\n",
    "    requirements_df.insert(req_cols_len, \"ClassifiedText\",\"\")\n",
    "    requirements_df.insert(req_cols_len+1, \"Keywords\",\"\")\n",
    "    requirements_df.insert(req_cols_len+2, \"DefectsMatchScore\",\"\")\n",
    "\n",
    "    defects_df.insert(def_cols_len, \"ClassifiedText\",\"\")\n",
    "    defects_df.insert(def_cols_len+1, \"Keywords\",\"\")\n",
    "    defects_df.insert(def_cols_len+2, \"TestCasesMatchScore\",\"\")\n",
    "\n",
    "    testcases_df.insert(tcs_cols_len, \"ClassifiedText\",\"\")\n",
    "    testcases_df.insert(tcs_cols_len+1, \"Keywords\",\"\")\n",
    "    testcases_df.insert(tcs_cols_len+2, \"RequirementsMatchScore\",\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2 Utility functions for Engineering Insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_text_classifier_output(artifact_df, config, output_column_name):\n",
    "    \"\"\" Add Watson text classifier output to the artifact dataframe\n",
    "    \"\"\"\n",
    "    for index, row in artifact_df.iterrows():\n",
    "        summary = row[\"Description\"]\n",
    "        classifier_journey_output = classify_text(summary, config)\n",
    "        artifact_df.set_value(index, output_column_name, classifier_journey_output)\n",
    "    return artifact_df \n",
    "           \n",
    "def add_keywords_entities(artifact_df, classify_text_column_name, output_column_name):\n",
    "    \"\"\" Add keywords and entities to the artifact dataframe\"\"\"\n",
    "    for index, artifact in artifact_df.iterrows():\n",
    "        keywords_array = []\n",
    "        for row in artifact[classify_text_column_name]['keywords']:\n",
    "            if not row['text'] in keywords_array:\n",
    "                keywords_array.append(row['text'])\n",
    "                \n",
    "        for entities in artifact[classify_text_column_name]['entities']:\n",
    "            if not entities['text'] in keywords_array:\n",
    "                keywords_array.append(entities['text'])\n",
    "            if not entities['type'] in keywords_array:\n",
    "                keywords_array.append(entities['type'])\n",
    "        artifact_df.set_value(index, output_column_name, keywords_array)\n",
    "    return artifact_df \n",
    "\n",
    "def populate_text_similarity_score(artifact_df1, artifact_df2, keywords_column_name, output_column_name):\n",
    "    \"\"\" Populate text similarity score to the artifact dataframes\n",
    "    \"\"\"\n",
    "    for index1, artifact1 in artifact_df1.iterrows():\n",
    "        matches = []\n",
    "        top_matches = []\n",
    "        for index2, artifact2 in artifact_df2.iterrows():\n",
    "            matches.append({'ID': artifact2['ID'], \n",
    "                            'cosine_score': 0, \n",
    "                            'SubjectID':artifact1['ID']})\n",
    "            cosine_score = compute_text_similarity(\n",
    "                artifact1['Description'], \n",
    "                artifact2['Description'], \n",
    "                artifact1['Keywords'], \n",
    "                artifact2['Keywords'])\n",
    "            matches[index2][\"cosine_score\"] = cosine_score\n",
    "       \n",
    "        sorted_obj = sorted(matches, key=lambda x : x['cosine_score'], reverse=True)\n",
    "      \n",
    "        for obj in sorted_obj:\n",
    "            if obj['cosine_score'] > 0.4:\n",
    "                top_matches.append(obj)\n",
    "               \n",
    "        artifact_df1.set_value(index1, output_column_name, top_matches)\n",
    "    return artifact_df1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.3 Process flow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Prepare data **\n",
    "* Load artifacts from object storage and create pandas dataframes\n",
    "* Prepare the pandas dataframes. Add additional columns required for further processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_artifacts()\n",
    "prepare_artifact_dataframes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Run Spacy Text Classifier on data **\n",
    "* Add the text classification output to the artifact dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_column_name = \"ClassifiedText\"\n",
    "defects_df = add_text_classifier_output(defects_df,config, output_column_name)\n",
    "testcases_df = add_text_classifier_output(testcases_df,config, output_column_name)\n",
    "requirements_df = add_text_classifier_output(requirements_df,config, output_column_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Populate keywords and entities **\n",
    "* Add the keywords and entities extracted from the unstructured text to the artifact dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Correlate keywords between artifacts **\n",
    "* Add the text similarity score of associated artifacts to the dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Utility functions to store entities and relations in Orient DB **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Transform results for Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Expose integration point with a websocket client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.1 Start websocket client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_websocket_listener()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
